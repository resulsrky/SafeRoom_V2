# ğŸ¬ SafeRoom Video Pipeline Optimizasyon Analizi

**Tarih:** 2024  
**Yazar:** Senior Performance Engineer  
**Durum:** Analiz TamamlandÄ±

---

## ğŸ“‘ Ä°Ã‡Ä°NDEKÄ°LER

1. [Mevcut Mimari Analizi](#1-mevcut-mimari-analizi)
2. [Kopya NoktalarÄ±nÄ±n Tespiti](#2-kopya-noktalarÄ±nÄ±n-tespiti)
3. [KÄ±sa Vadeli Mikro Optimizasyonlar](#3-kÄ±sa-vadeli-mikro-optimizasyonlar)
4. [Orta Vadeli GPU Renderer Mimarisi](#4-orta-vadeli-gpu-renderer-mimarisi)
5. [JavaFX UI AyrÄ±ÅŸtÄ±rma Stratejisi](#5-javafx-ui-ayrÄ±ÅŸtÄ±rma-stratejisi)
6. [SonuÃ§ Raporu ve TODO](#6-sonuÃ§-raporu-ve-todo)

---

## 1. MEVCUT MÄ°MARÄ° ANALÄ°ZÄ°

### 1.1 Video Pipeline AkÄ±ÅŸÄ± (Mevcut Durum)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     MEVCUT VIDEO PIPELINE (CPU-BOUND)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ WebRTC C++   â”‚â”€â”€â”€â–¶â”‚ JNI Bridge   â”‚â”€â”€â”€â–¶â”‚ VideoFrame   â”‚â”€â”€â”€â–¶â”‚ I420     â”‚   â”‚
â”‚  â”‚ Decoder      â”‚    â”‚ (dev.onvoid) â”‚    â”‚ Java Object  â”‚    â”‚ Buffer   â”‚   â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚              â”‚    â”‚          â”‚   â”‚
â”‚  â”‚ GPU/CPU      â”‚    â”‚ COPY #1      â”‚    â”‚ retain()     â”‚    â”‚ YUV Data â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                   â”‚                   â”‚                  â”‚        â”‚
â”‚         â–¼                   â–¼                   â–¼                  â–¼        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Frame        â”‚â”€â”€â”€â–¶â”‚ Convert      â”‚â”€â”€â”€â–¶â”‚ int[] ARGB   â”‚â”€â”€â”€â–¶â”‚ Pixel    â”‚   â”‚
â”‚  â”‚ Processor    â”‚    â”‚ I420â†’ARGB    â”‚    â”‚ Buffer Pool  â”‚    â”‚ Writer   â”‚   â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚              â”‚    â”‚          â”‚   â”‚
â”‚  â”‚ Platform     â”‚    â”‚ COPY #2      â”‚    â”‚ COPY #3      â”‚    â”‚ COPY #4  â”‚   â”‚
â”‚  â”‚ Thread       â”‚    â”‚ (per pixel)  â”‚    â”‚ (to pool)    â”‚    â”‚ (setPixels)  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                   â”‚                   â”‚                  â”‚        â”‚
â”‚         â–¼                   â–¼                   â–¼                  â–¼        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Writable     â”‚â”€â”€â”€â–¶â”‚ Graphics     â”‚â”€â”€â”€â–¶â”‚ JavaFX       â”‚â”€â”€â”€â–¶â”‚ GPU      â”‚   â”‚
â”‚  â”‚ Image        â”‚    â”‚ Context      â”‚    â”‚ SceneGraph   â”‚    â”‚ (Prism)  â”‚   â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚              â”‚    â”‚          â”‚   â”‚
â”‚  â”‚ COPY #5      â”‚    â”‚ drawImage()  â”‚    â”‚ REPAINT      â”‚    â”‚ Render   â”‚   â”‚
â”‚  â”‚ (to texture) â”‚    â”‚              â”‚    â”‚ (every frame)â”‚    â”‚          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 SÄ±nÄ±f Rolleri

| SÄ±nÄ±f | Dosya | Rol | Kritik Ä°ÅŸlem |
|-------|-------|-----|--------------|
| `VideoPanel` | `gui/components/VideoPanel.java` | JavaFX Canvas, video render | `paintFrame()` - PixelWriter |
| `FrameProcessor` | `webrtc/pipeline/FrameProcessor.java` | I420â†’ARGB dÃ¶nÃ¼ÅŸÃ¼mÃ¼ | `convertFrame()` - pixel loop |
| `FrameRenderResult` | `webrtc/pipeline/FrameRenderResult.java` | ARGB buffer container | `fromI420()` - YUVâ†’RGB |
| `ArgbBufferPool` | `webrtc/pipeline/ArgbBufferPool.java` | Buffer pool (reuse) | `acquire()/release()` |
| `VideoTrackSink` | dev.onvoid.webrtc | WebRTC callback | JNI frame delivery |

---

## 2. KOPYA NOKTALARININ TESPÄ°TÄ°

### 2.1 Tespit Edilen Kopyalar (640x480 @ 30 FPS iÃ§in)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ KOPYA  â”‚ KONUM                                â”‚ BOYUT/FRAME   â”‚ MB/saniye    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ #1     â”‚ WebRTC C++ â†’ Java (JNI)              â”‚ ~460KB        â”‚ 13.5 MB/s    â”‚
â”‚        â”‚ I420Buffer native â†’ ByteBuffer       â”‚ (YUV 4:2:0)   â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ #2     â”‚ I420 â†’ ARGB Conversion               â”‚ ~1.2MB        â”‚ 36 MB/s      â”‚
â”‚        â”‚ FrameRenderResult.fromI420()         â”‚ (32-bit ARGB) â”‚              â”‚
â”‚        â”‚ âš ï¸ PER-PIXEL LOOP (O(width*height))  â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ #3     â”‚ int[] â†’ PixelWriter.setPixels()      â”‚ ~1.2MB        â”‚ 36 MB/s      â”‚
â”‚        â”‚ VideoPanel.paintFrame() line 170     â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ #4     â”‚ WritableImage â†’ GPU Texture          â”‚ ~1.2MB        â”‚ 36 MB/s      â”‚
â”‚        â”‚ JavaFX Prism pipeline (internal)     â”‚ (Prism copy)  â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOPLAM â”‚                                      â”‚ ~4.1MB/frame  â”‚ ~120 MB/s    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 En Kritik DarboÄŸaz: `fromI420()` (KOPYA #2)

```java
// ğŸ“ FrameRenderResult.java:44-79
// âš ï¸ BU DÃ–NGÃœ HER FRAME Ä°Ã‡Ä°N width*height = 307,200 Ä°TERASYON

public static FrameRenderResult fromI420(I420Buffer buffer, long timestampNs) {
    int width = buffer.getWidth();   // 640
    int height = buffer.getHeight(); // 480
    int[] argb = BUFFER_POOL.acquire(width, height);

    // YUV plane'lerden okuma (JNI indirect ByteBuffer)
    ByteBuffer yPlane = buffer.getDataY();  // âš ï¸ Her get() = JNI call olabilir
    ByteBuffer uPlane = buffer.getDataU();
    ByteBuffer vPlane = buffer.getDataV();

    // âš ï¸âš ï¸âš ï¸ PER-PIXEL LOOP - EN BÃœYÃœK DARBOÄAZ âš ï¸âš ï¸âš ï¸
    for (int y = 0; y < height; y++) {         // 480 iteration
        for (int x = 0; x < width; x++) {      // 640 iteration
            // Her pixel iÃ§in:
            // - 3x ByteBuffer.get() (potansiyel JNI overhead)
            // - 7x integer math
            // - 3x clamp() function call
            // - 1x array write
            
            int yIndex = y * yStride + x;
            int uvIndex = (y / 2) * uStride + (x / 2);
            int vIndex = (y / 2) * vStride + (x / 2);

            int Y = (yPlane.get(yIndex) & 0xFF) - 16;
            int U = (uPlane.get(uvIndex) & 0xFF) - 128;
            int V = (vPlane.get(vIndex) & 0xFF) - 128;

            // YUV to RGB conversion (integer math)
            int R = (298 * Y + 409 * V + 128) >> 8;
            int G = (298 * Y - 100 * U - 208 * V + 128) >> 8;
            int B = (298 * Y + 516 * U + 128) >> 8;

            R = clamp(R);
            G = clamp(G);
            B = clamp(B);

            argb[y * width + x] = 0xFF000000 | (R << 16) | (G << 8) | B;
        }
    }
    return new FrameRenderResult(width, height, argb, timestampNs);
}
```

### 2.3 Maliyet Analizi

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FRAME BAÅINA MALÄ°YET (640x480 @ 30 FPS)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  Per-Frame:                                                         â”‚
â”‚  â”œâ”€â”€ fromI420() loop iterations:     307,200                        â”‚
â”‚  â”œâ”€â”€ ByteBuffer.get() calls:         921,600 (3 per pixel)          â”‚
â”‚  â”œâ”€â”€ Integer operations:             2,150,400 (7 per pixel)        â”‚
â”‚  â”œâ”€â”€ clamp() calls:                  921,600 (3 per pixel)          â”‚
â”‚  â”œâ”€â”€ Array writes:                   307,200                        â”‚
â”‚  â”‚                                                                  â”‚
â”‚  Per-Second (30 FPS):                                               â”‚
â”‚  â”œâ”€â”€ Total iterations:               9,216,000                      â”‚
â”‚  â”œâ”€â”€ ByteBuffer.get():               27,648,000                     â”‚
â”‚  â”œâ”€â”€ Memory bandwidth:               ~120 MB/s (just copies)        â”‚
â”‚  â”‚                                                                  â”‚
â”‚  GC Pressure:                                                       â”‚
â”‚  â”œâ”€â”€ Buffer pool helps, but:                                        â”‚
â”‚  â”‚   â””â”€â”€ Resolution change = new allocation                         â”‚
â”‚  â”‚   â””â”€â”€ Pool miss = new int[307200] = 1.2 MB heap                  â”‚
â”‚  â”‚                                                                  â”‚
â”‚  4-6 Participant Meeting:                                           â”‚
â”‚  â”œâ”€â”€ 6 Ã— 120 MB/s = 720 MB/s memory copying                         â”‚
â”‚  â”œâ”€â”€ 6 Ã— 9.2M iterations = 55.2M iterations/second                  â”‚
â”‚  â””â”€â”€ âš ï¸ CPU SATURATION GUARANTEED                                   â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. KISA VADELÄ° MÄ°KRO OPTÄ°MÄ°ZASYONLAR

### 3.1 Optimizasyon A: SIMD-style Batch Processing

Mevcut per-pixel loop yerine row-based batch processing:

```java
// ğŸ“ FrameRenderResult.java - Ã–NCE (mevcut kod)
// Her pixel iÃ§in ayrÄ± ayrÄ± iÅŸlem

// ğŸ“ FrameRenderResult.java - SONRA (optimizasyon)
public static FrameRenderResult fromI420Optimized(I420Buffer buffer, long timestampNs) {
    int width = buffer.getWidth();
    int height = buffer.getHeight();
    int[] argb = BUFFER_POOL.acquire(width, height);

    // âœ… Direct buffer access - bulk get yerine position-based
    ByteBuffer yPlane = buffer.getDataY();
    ByteBuffer uPlane = buffer.getDataU();
    ByteBuffer vPlane = buffer.getDataV();

    int yStride = buffer.getStrideY();
    int uStride = buffer.getStrideU();
    int vStride = buffer.getStrideV();

    // âœ… Pre-allocate row buffers (reusable across frames)
    byte[] yRow = TL_Y_ROW.get();
    byte[] uRow = TL_U_ROW.get();
    byte[] vRow = TL_V_ROW.get();
    
    ensureRowBufferSize(yRow, width);
    ensureRowBufferSize(uRow, (width + 1) / 2);
    ensureRowBufferSize(vRow, (width + 1) / 2);

    int halfWidth = (width + 1) / 2;
    
    for (int y = 0; y < height; y++) {
        // âœ… Bulk read entire Y row (single JNI call instead of width calls)
        yPlane.position(y * yStride);
        yPlane.get(yRow, 0, width);
        
        // âœ… Read UV rows only when needed (every 2 rows)
        int uvY = y / 2;
        if ((y & 1) == 0) {
            uPlane.position(uvY * uStride);
            uPlane.get(uRow, 0, halfWidth);
            vPlane.position(uvY * vStride);
            vPlane.get(vRow, 0, halfWidth);
        }
        
        // âœ… Process row with local array access (much faster than ByteBuffer.get)
        int rowOffset = y * width;
        for (int x = 0; x < width; x++) {
            int uvX = x / 2;
            
            int Y = (yRow[x] & 0xFF) - 16;
            int U = (uRow[uvX] & 0xFF) - 128;
            int V = (vRow[uvX] & 0xFF) - 128;

            // âœ… Inline clamp with Math.max/min (JIT optimizes better)
            int R = Math.max(0, Math.min(255, (298 * Y + 409 * V + 128) >> 8));
            int G = Math.max(0, Math.min(255, (298 * Y - 100 * U - 208 * V + 128) >> 8));
            int B = Math.max(0, Math.min(255, (298 * Y + 516 * U + 128) >> 8));

            argb[rowOffset + x] = 0xFF000000 | (R << 16) | (G << 8) | B;
        }
    }
    
    // Reset buffer positions
    yPlane.rewind();
    uPlane.rewind();
    vPlane.rewind();

    return new FrameRenderResult(width, height, argb, timestampNs);
}

// ThreadLocal row buffers to avoid allocation
private static final ThreadLocal<byte[]> TL_Y_ROW = ThreadLocal.withInitial(() -> new byte[1920]);
private static final ThreadLocal<byte[]> TL_U_ROW = ThreadLocal.withInitial(() -> new byte[960]);
private static final ThreadLocal<byte[]> TL_V_ROW = ThreadLocal.withInitial(() -> new byte[960]);

private static void ensureRowBufferSize(byte[] buffer, int required) {
    // Buffers are pre-allocated for 1080p, should be enough for most cases
    if (buffer.length < required) {
        throw new IllegalStateException("Row buffer too small: " + buffer.length + " < " + required);
    }
}
```

**Beklenen Ä°yileÅŸme:**
- ByteBuffer.get() Ã§aÄŸrÄ±larÄ±: 921,600 â†’ ~960 (row sayÄ±sÄ± kadar)
- ~**95% azalma** JNI overhead'de

### 3.2 Optimizasyon B: Reusable WritableImage

```java
// ğŸ“ VideoPanel.java - Ã–NCE (line 165-167)
if (videoImage == null || videoImage.getWidth() != width || videoImage.getHeight() != height) {
    videoImage = new WritableImage(width, height);  // âš ï¸ Her resolution deÄŸiÅŸikliÄŸinde GC
}

// ğŸ“ VideoPanel.java - SONRA
// WritableImage'Ä± daha uzun sÃ¼re tutarak GC pressure azalt
private WritableImage videoImage;
private int cachedWidth = -1;
private int cachedHeight = -1;

private void ensureVideoImage(int width, int height) {
    // âœ… Sadece boyut deÄŸiÅŸtiÄŸinde yeni image oluÅŸtur
    if (cachedWidth != width || cachedHeight != height) {
        // Eski image'Ä± null'a set et (GC'ye bÄ±rak)
        videoImage = null;
        
        // Yeni image oluÅŸtur
        videoImage = new WritableImage(width, height);
        cachedWidth = width;
        cachedHeight = height;
        
        System.out.printf("[VideoPanel] New WritableImage allocated: %dx%d%n", width, height);
    }
}
```

### 3.3 Optimizasyon C: Frame Rate Throttling

```java
// ğŸ“ VideoPanel.java - Yeni field ekle
private static final long TARGET_FRAME_INTERVAL_NS = 1_000_000_000L / 30; // 30 FPS target
private long lastPaintTimeNs = 0;

// ğŸ“ AnimationTimer.handle() iÃ§inde
@Override
public void handle(long now) {
    if (!isActive || renderingPaused) {
        return;
    }
    
    // âœ… Frame rate throttling - 30 FPS'ten fazla paint etme
    if (now - lastPaintTimeNs < TARGET_FRAME_INTERVAL_NS) {
        return; // Skip this frame, too soon
    }
    
    FrameRenderResult frame = latestFrame.getAndSet(null);
    if (frame != null) {
        try {
            paintFrame(frame);
            lastPaintTimeNs = now;
            // ... rest of the code
        } finally {
            frame.release();
        }
    }
}
```

### 3.4 Optimizasyon D: IntBuffer Direct Write

```java
// ğŸ“ VideoPanel.java - Ã–NCE
PixelWriter pixelWriter = videoImage.getPixelWriter();
pixelWriter.setPixels(0, 0, width, height, ARGB_FORMAT, frame.getArgbPixels(), 0, width);

// ğŸ“ VideoPanel.java - SONRA (IntBuffer wrap ile zero-copy)
private IntBuffer intBufferWrapper;

private void paintFrameOptimized(FrameRenderResult frame) {
    int width = frame.getWidth();
    int height = frame.getHeight();
    
    ensureVideoImage(width, height);
    
    int[] pixels = frame.getArgbPixels();
    
    // âœ… Wrap existing array - NO COPY
    if (intBufferWrapper == null || intBufferWrapper.capacity() < pixels.length) {
        intBufferWrapper = IntBuffer.allocate(width * height);
    }
    intBufferWrapper.clear();
    intBufferWrapper.put(pixels);
    intBufferWrapper.flip();
    
    // âœ… Use IntBuffer version - potentially more efficient
    PixelWriter pixelWriter = videoImage.getPixelWriter();
    pixelWriter.setPixels(0, 0, width, height, ARGB_FORMAT, intBufferWrapper, width);
    
    // Draw to canvas
    gc.drawImage(videoImage, drawX, drawY, drawWidth, drawHeight);
}
```

---

## 4. ORTA VADELÄ° GPU RENDERER MÄ°MARÄ°SÄ°

### 4.1 Hedef Mimari

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     HEDEF VIDEO PIPELINE (GPU-ACCELERATED)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ WebRTC C++   â”‚â”€â”€â”€â–¶â”‚ Native GPU   â”‚â”€â”€â”€â–¶â”‚ GPU Texture  â”‚â”€â”€â”€â–¶â”‚ Display  â”‚  â”‚
â”‚  â”‚ Decoder      â”‚    â”‚ Renderer     â”‚    â”‚ (NV12/RGBA)  â”‚    â”‚ Surface  â”‚  â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚              â”‚    â”‚          â”‚  â”‚
â”‚  â”‚ HW Decode    â”‚    â”‚ ZERO-COPY    â”‚    â”‚ GPU Memory   â”‚    â”‚ Direct   â”‚  â”‚
â”‚  â”‚ (VideoToolboxâ”‚    â”‚ Texture      â”‚    â”‚ Only         â”‚    â”‚ Render   â”‚  â”‚
â”‚  â”‚  NVENC, VAAPIâ”‚    â”‚ Upload       â”‚    â”‚              â”‚    â”‚          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                                                          â”‚        â”‚
â”‚         â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚        â”‚
â”‚         â”‚            â”‚      JavaFX UI OVERLAY           â”‚          â”‚        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  (buttons, labels, controls)     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                      â”‚  Transparan, GPU Ã¼zerinde        â”‚                   â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                              â”‚
â”‚  âœ… CPU'ya frame kopyasÄ± YOK                                                 â”‚
â”‚  âœ… Java heap allocation YOK                                                 â”‚
â”‚  âœ… YUVâ†’RGB dÃ¶nÃ¼ÅŸÃ¼mÃ¼ GPU shader'da                                          â”‚
â”‚  âœ… JavaFX sadece UI iÃ§in                                                    â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Java Interface TasarÄ±mÄ±

```java
// ğŸ“ Yeni dosya: src/main/java/com/saferoom/webrtc/gpu/NativeVideoRenderer.java

package com.saferoom.webrtc.gpu;

import dev.onvoid.webrtc.media.video.VideoFrame;
import dev.onvoid.webrtc.media.video.VideoTrackSink;

/**
 * GPU-accelerated video renderer interface.
 * 
 * Bu interface, video frame'leri doÄŸrudan GPU texture'a render eder.
 * Java heap'e hiÃ§bir kopya yapÄ±lmaz.
 * 
 * Lifecycle:
 * 1. initialize() - GPU context ve surface oluÅŸtur
 * 2. onFrame() - Her frame iÃ§in Ã§aÄŸrÄ±lÄ±r (VideoTrackSink callback)
 * 3. resize() - Pencere boyutu deÄŸiÅŸtiÄŸinde
 * 4. dispose() - Cleanup
 */
public interface NativeVideoRenderer extends VideoTrackSink, AutoCloseable {

    /**
     * GPU renderer'Ä± baÅŸlat.
     * 
     * @param windowHandle Platform-specific window handle
     *                     Windows: HWND
     *                     macOS: NSView pointer
     *                     Linux: X11 Window ID veya Wayland surface
     * @param width Initial width
     * @param height Initial height
     * @return true if successful
     */
    boolean initialize(long windowHandle, int width, int height);

    /**
     * Render surface boyutunu gÃ¼ncelle.
     */
    void resize(int width, int height);

    /**
     * Renderer'Ä± duraklat (pencere minimize edildiÄŸinde).
     */
    void pause();

    /**
     * Renderer'Ä± devam ettir.
     */
    void resume();

    /**
     * Mevcut frame'in render edilip edilmediÄŸini kontrol et.
     */
    boolean isRendering();

    /**
     * Son frame'in timestamp'ini al (debugging iÃ§in).
     */
    long getLastFrameTimestampNs();

    /**
     * Cleanup - GPU kaynaklarÄ±nÄ± serbest bÄ±rak.
     */
    @Override
    void close();
}
```

### 4.3 JNI Bridge TasarÄ±mÄ±

```java
// ğŸ“ Yeni dosya: src/main/java/com/saferoom/webrtc/gpu/NativeGpuRendererBridge.java

package com.saferoom.webrtc.gpu;

import dev.onvoid.webrtc.media.video.VideoFrame;

/**
 * JNI bridge for native GPU video rendering.
 * 
 * Bu sÄ±nÄ±f, C++ tarafÄ±ndaki platform-specific renderer ile konuÅŸur.
 * 
 * Native library yÃ¼kleme sÄ±rasÄ±:
 * 1. Windows: saferoom-gpu-win.dll
 * 2. macOS: libsaferoom-gpu-mac.dylib
 * 3. Linux: libsaferoom-gpu-linux.so
 */
public final class NativeGpuRendererBridge implements NativeVideoRenderer {

    // Native pointer to C++ renderer instance
    private long nativeHandle = 0;
    
    // State tracking
    private volatile boolean initialized = false;
    private volatile boolean rendering = false;
    private volatile long lastFrameTimestampNs = 0;

    static {
        loadNativeLibrary();
    }

    private static void loadNativeLibrary() {
        String osName = System.getProperty("os.name").toLowerCase();
        String libName;
        
        if (osName.contains("win")) {
            libName = "saferoom-gpu-win";
        } else if (osName.contains("mac")) {
            libName = "saferoom-gpu-mac";
        } else {
            libName = "saferoom-gpu-linux";
        }
        
        try {
            System.loadLibrary(libName);
            System.out.println("[NativeGpuRenderer] Loaded native library: " + libName);
        } catch (UnsatisfiedLinkError e) {
            System.err.println("[NativeGpuRenderer] Failed to load native library: " + libName);
            throw e;
        }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // PUBLIC API
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    @Override
    public boolean initialize(long windowHandle, int width, int height) {
        if (initialized) {
            System.err.println("[NativeGpuRenderer] Already initialized");
            return false;
        }
        
        nativeHandle = nativeCreateRenderer(windowHandle, width, height);
        if (nativeHandle == 0) {
            System.err.println("[NativeGpuRenderer] Failed to create native renderer");
            return false;
        }
        
        initialized = true;
        System.out.printf("[NativeGpuRenderer] Initialized: %dx%d%n", width, height);
        return true;
    }

    @Override
    public void onVideoFrame(VideoFrame frame) {
        if (!initialized || nativeHandle == 0) {
            return;
        }
        
        // âœ… Frame'i doÄŸrudan native'e gÃ¶nder - Java'da iÅŸlem YOK
        // Native taraf frame.buffer'dan GPU texture'a upload yapacak
        rendering = true;
        try {
            nativeRenderFrame(nativeHandle, frame);
            lastFrameTimestampNs = frame.timestampNs;
        } finally {
            rendering = false;
        }
    }

    @Override
    public void resize(int width, int height) {
        if (initialized && nativeHandle != 0) {
            nativeResize(nativeHandle, width, height);
        }
    }

    @Override
    public void pause() {
        if (initialized && nativeHandle != 0) {
            nativePause(nativeHandle);
        }
    }

    @Override
    public void resume() {
        if (initialized && nativeHandle != 0) {
            nativeResume(nativeHandle);
        }
    }

    @Override
    public boolean isRendering() {
        return rendering;
    }

    @Override
    public long getLastFrameTimestampNs() {
        return lastFrameTimestampNs;
    }

    @Override
    public void close() {
        if (nativeHandle != 0) {
            nativeDestroyRenderer(nativeHandle);
            nativeHandle = 0;
            initialized = false;
            System.out.println("[NativeGpuRenderer] Destroyed");
        }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // NATIVE METHODS
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    /**
     * Create native renderer instance.
     * @return Native pointer (0 on failure)
     */
    private static native long nativeCreateRenderer(long windowHandle, int width, int height);

    /**
     * Render a video frame to the GPU surface.
     * The native implementation will:
     * 1. Extract I420/NV12 buffer from VideoFrame
     * 2. Upload to GPU texture (zero-copy if possible)
     * 3. Convert YUVâ†’RGB in shader
     * 4. Display on surface
     */
    private static native void nativeRenderFrame(long handle, VideoFrame frame);

    /**
     * Resize the render surface.
     */
    private static native void nativeResize(long handle, int width, int height);

    /**
     * Pause rendering (release GPU resources temporarily).
     */
    private static native void nativePause(long handle);

    /**
     * Resume rendering.
     */
    private static native void nativeResume(long handle);

    /**
     * Destroy the native renderer and release all resources.
     */
    private static native void nativeDestroyRenderer(long handle);
}
```

### 4.4 C++ Native Renderer Ä°skeleti

```cpp
// ğŸ“ Yeni dosya: native/src/gpu_renderer.h

#ifndef SAFEROOM_GPU_RENDERER_H
#define SAFEROOM_GPU_RENDERER_H

#include <cstdint>

namespace saferoom {

/**
 * Abstract base class for platform-specific GPU video renderers.
 * 
 * Lifecycle:
 * 1. Constructor - Platform detection
 * 2. initialize() - Create GPU context and surface
 * 3. renderFrame() - Upload and display video frame
 * 4. resize() - Handle window resize
 * 5. Destructor - Cleanup
 */
class GpuRenderer {
public:
    virtual ~GpuRenderer() = default;

    /**
     * Initialize the renderer with a window handle.
     * 
     * @param windowHandle Platform-specific window handle
     * @param width Initial width
     * @param height Initial height
     * @return true on success
     */
    virtual bool initialize(void* windowHandle, int width, int height) = 0;

    /**
     * Render a video frame.
     * 
     * The implementation should:
     * 1. Accept YUV (I420/NV12) data
     * 2. Upload to GPU texture
     * 3. Convert to RGB in shader
     * 4. Display on surface
     * 
     * @param yPlane Y plane data
     * @param uPlane U plane data
     * @param vPlane V plane data
     * @param yStride Y plane stride
     * @param uStride U plane stride
     * @param vStride V plane stride
     * @param width Frame width
     * @param height Frame height
     */
    virtual void renderFrame(
        const uint8_t* yPlane, const uint8_t* uPlane, const uint8_t* vPlane,
        int yStride, int uStride, int vStride,
        int width, int height) = 0;

    /**
     * Resize the render surface.
     */
    virtual void resize(int width, int height) = 0;

    /**
     * Pause rendering.
     */
    virtual void pause() = 0;

    /**
     * Resume rendering.
     */
    virtual void resume() = 0;

    /**
     * Check if renderer is active.
     */
    virtual bool isActive() const = 0;

    // Factory method - creates platform-specific renderer
    static GpuRenderer* create();
};

} // namespace saferoom

#endif // SAFEROOM_GPU_RENDERER_H
```

### 4.5 Windows Direct3D11 Renderer Ä°skeleti

```cpp
// ğŸ“ Yeni dosya: native/src/win/d3d11_renderer.cpp

#ifdef _WIN32

#include "../gpu_renderer.h"
#include <d3d11.h>
#include <dxgi.h>
#include <wrl/client.h>

using Microsoft::WRL::ComPtr;

namespace saferoom {

/**
 * Direct3D 11 implementation of GpuRenderer.
 * 
 * Video flow:
 * 1. Receive I420 buffer from WebRTC
 * 2. Upload Y/U/V planes to 3 separate textures
 * 3. Run YUVâ†’RGB pixel shader
 * 4. Present to swap chain
 */
class D3D11Renderer : public GpuRenderer {
public:
    D3D11Renderer() = default;
    ~D3D11Renderer() override { cleanup(); }

    bool initialize(void* windowHandle, int width, int height) override {
        HWND hwnd = static_cast<HWND>(windowHandle);
        
        // Create device and swap chain
        DXGI_SWAP_CHAIN_DESC scd = {};
        scd.BufferCount = 2;
        scd.BufferDesc.Width = width;
        scd.BufferDesc.Height = height;
        scd.BufferDesc.Format = DXGI_FORMAT_R8G8B8A8_UNORM;
        scd.BufferUsage = DXGI_USAGE_RENDER_TARGET_OUTPUT;
        scd.OutputWindow = hwnd;
        scd.SampleDesc.Count = 1;
        scd.Windowed = TRUE;
        scd.SwapEffect = DXGI_SWAP_EFFECT_FLIP_DISCARD;

        D3D_FEATURE_LEVEL featureLevel;
        HRESULT hr = D3D11CreateDeviceAndSwapChain(
            nullptr,                    // Adapter
            D3D_DRIVER_TYPE_HARDWARE,   // Hardware acceleration
            nullptr,                    // Software module
            0,                          // Flags
            nullptr, 0,                 // Feature levels
            D3D11_SDK_VERSION,
            &scd,
            &swapChain_,
            &device_,
            &featureLevel,
            &context_
        );

        if (FAILED(hr)) {
            return false;
        }

        createRenderTarget(width, height);
        createYuvTextures(width, height);
        createShaders();
        
        active_ = true;
        return true;
    }

    void renderFrame(
        const uint8_t* yPlane, const uint8_t* uPlane, const uint8_t* vPlane,
        int yStride, int uStride, int vStride,
        int width, int height) override 
    {
        if (!active_) return;

        // 1. Update Y texture
        D3D11_MAPPED_SUBRESOURCE mapped;
        context_->Map(yTexture_.Get(), 0, D3D11_MAP_WRITE_DISCARD, 0, &mapped);
        for (int y = 0; y < height; y++) {
            memcpy(
                static_cast<uint8_t*>(mapped.pData) + y * mapped.RowPitch,
                yPlane + y * yStride,
                width
            );
        }
        context_->Unmap(yTexture_.Get(), 0);

        // 2. Update U texture
        context_->Map(uTexture_.Get(), 0, D3D11_MAP_WRITE_DISCARD, 0, &mapped);
        int uvHeight = (height + 1) / 2;
        int uvWidth = (width + 1) / 2;
        for (int y = 0; y < uvHeight; y++) {
            memcpy(
                static_cast<uint8_t*>(mapped.pData) + y * mapped.RowPitch,
                uPlane + y * uStride,
                uvWidth
            );
        }
        context_->Unmap(uTexture_.Get(), 0);

        // 3. Update V texture
        context_->Map(vTexture_.Get(), 0, D3D11_MAP_WRITE_DISCARD, 0, &mapped);
        for (int y = 0; y < uvHeight; y++) {
            memcpy(
                static_cast<uint8_t*>(mapped.pData) + y * mapped.RowPitch,
                vPlane + y * vStride,
                uvWidth
            );
        }
        context_->Unmap(vTexture_.Get(), 0);

        // 4. Bind YUV textures and run shader
        ID3D11ShaderResourceView* srvs[] = { ySrv_.Get(), uSrv_.Get(), vSrv_.Get() };
        context_->PSSetShaderResources(0, 3, srvs);
        context_->PSSetShader(pixelShader_.Get(), nullptr, 0);
        context_->VSSetShader(vertexShader_.Get(), nullptr, 0);
        
        // 5. Draw fullscreen quad
        context_->IASetPrimitiveTopology(D3D11_PRIMITIVE_TOPOLOGY_TRIANGLESTRIP);
        context_->Draw(4, 0);

        // 6. Present
        swapChain_->Present(1, 0); // VSync
    }

    void resize(int width, int height) override {
        if (!active_) return;
        
        // Release old resources
        renderTargetView_.Reset();
        
        // Resize swap chain
        swapChain_->ResizeBuffers(0, width, height, DXGI_FORMAT_UNKNOWN, 0);
        
        // Recreate render target
        createRenderTarget(width, height);
        
        // Recreate YUV textures
        createYuvTextures(width, height);
    }

    void pause() override { active_ = false; }
    void resume() override { active_ = true; }
    bool isActive() const override { return active_; }

private:
    void cleanup() {
        active_ = false;
        // ComPtr handles release automatically
    }

    void createRenderTarget(int width, int height) {
        ComPtr<ID3D11Texture2D> backBuffer;
        swapChain_->GetBuffer(0, IID_PPV_ARGS(&backBuffer));
        device_->CreateRenderTargetView(backBuffer.Get(), nullptr, &renderTargetView_);
        context_->OMSetRenderTargets(1, renderTargetView_.GetAddressOf(), nullptr);

        D3D11_VIEWPORT vp = { 0, 0, (float)width, (float)height, 0, 1 };
        context_->RSSetViewports(1, &vp);
    }

    void createYuvTextures(int width, int height) {
        D3D11_TEXTURE2D_DESC desc = {};
        desc.Width = width;
        desc.Height = height;
        desc.MipLevels = 1;
        desc.ArraySize = 1;
        desc.Format = DXGI_FORMAT_R8_UNORM;
        desc.SampleDesc.Count = 1;
        desc.Usage = D3D11_USAGE_DYNAMIC;
        desc.BindFlags = D3D11_BIND_SHADER_RESOURCE;
        desc.CPUAccessFlags = D3D11_CPU_ACCESS_WRITE;

        device_->CreateTexture2D(&desc, nullptr, &yTexture_);
        device_->CreateShaderResourceView(yTexture_.Get(), nullptr, &ySrv_);

        desc.Width = (width + 1) / 2;
        desc.Height = (height + 1) / 2;
        device_->CreateTexture2D(&desc, nullptr, &uTexture_);
        device_->CreateShaderResourceView(uTexture_.Get(), nullptr, &uSrv_);
        
        device_->CreateTexture2D(&desc, nullptr, &vTexture_);
        device_->CreateShaderResourceView(vTexture_.Get(), nullptr, &vSrv_);
    }

    void createShaders() {
        // YUV to RGB pixel shader (HLSL)
        const char* psCode = R"(
            Texture2D yTex : register(t0);
            Texture2D uTex : register(t1);
            Texture2D vTex : register(t2);
            SamplerState samp : register(s0);
            
            float4 main(float4 pos : SV_POSITION, float2 uv : TEXCOORD) : SV_TARGET {
                float y = yTex.Sample(samp, uv).r;
                float u = uTex.Sample(samp, uv).r - 0.5;
                float v = vTex.Sample(samp, uv).r - 0.5;
                
                float r = y + 1.402 * v;
                float g = y - 0.344 * u - 0.714 * v;
                float b = y + 1.772 * u;
                
                return float4(saturate(float3(r, g, b)), 1.0);
            }
        )";
        
        // Compile and create shaders...
        // (Simplified - actual implementation needs D3DCompile)
    }

    ComPtr<ID3D11Device> device_;
    ComPtr<ID3D11DeviceContext> context_;
    ComPtr<IDXGISwapChain> swapChain_;
    ComPtr<ID3D11RenderTargetView> renderTargetView_;
    
    ComPtr<ID3D11Texture2D> yTexture_, uTexture_, vTexture_;
    ComPtr<ID3D11ShaderResourceView> ySrv_, uSrv_, vSrv_;
    
    ComPtr<ID3D11VertexShader> vertexShader_;
    ComPtr<ID3D11PixelShader> pixelShader_;
    
    bool active_ = false;
};

// Factory implementation for Windows
GpuRenderer* GpuRenderer::create() {
    return new D3D11Renderer();
}

} // namespace saferoom

#endif // _WIN32
```

### 4.6 Linux OpenGL Renderer Ä°skeleti

```cpp
// ğŸ“ Yeni dosya: native/src/linux/gl_renderer.cpp

#ifdef __linux__

#include "../gpu_renderer.h"
#include <GL/glx.h>
#include <GL/gl.h>
#include <X11/Xlib.h>

namespace saferoom {

/**
 * OpenGL implementation of GpuRenderer for Linux.
 * Uses GLX for X11 window integration.
 */
class GlRenderer : public GpuRenderer {
public:
    GlRenderer() = default;
    ~GlRenderer() override { cleanup(); }

    bool initialize(void* windowHandle, int width, int height) override {
        window_ = (Window)windowHandle;
        display_ = XOpenDisplay(nullptr);
        if (!display_) return false;

        // GLX configuration
        int attribs[] = {
            GLX_RGBA,
            GLX_DEPTH_SIZE, 24,
            GLX_DOUBLEBUFFER,
            None
        };
        
        XVisualInfo* vi = glXChooseVisual(display_, 0, attribs);
        if (!vi) return false;

        context_ = glXCreateContext(display_, vi, nullptr, GL_TRUE);
        glXMakeCurrent(display_, window_, context_);

        // Create YUV textures
        glGenTextures(3, textures_);
        for (int i = 0; i < 3; i++) {
            glBindTexture(GL_TEXTURE_2D, textures_[i]);
            glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
            glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
        }

        createShaderProgram();
        
        width_ = width;
        height_ = height;
        active_ = true;
        return true;
    }

    void renderFrame(
        const uint8_t* yPlane, const uint8_t* uPlane, const uint8_t* vPlane,
        int yStride, int uStride, int vStride,
        int width, int height) override 
    {
        if (!active_) return;

        glXMakeCurrent(display_, window_, context_);

        // Upload Y texture
        glActiveTexture(GL_TEXTURE0);
        glBindTexture(GL_TEXTURE_2D, textures_[0]);
        glPixelStorei(GL_UNPACK_ROW_LENGTH, yStride);
        glTexImage2D(GL_TEXTURE_2D, 0, GL_RED, width, height, 0, GL_RED, GL_UNSIGNED_BYTE, yPlane);

        // Upload U texture
        int uvWidth = (width + 1) / 2;
        int uvHeight = (height + 1) / 2;
        glActiveTexture(GL_TEXTURE1);
        glBindTexture(GL_TEXTURE_2D, textures_[1]);
        glPixelStorei(GL_UNPACK_ROW_LENGTH, uStride);
        glTexImage2D(GL_TEXTURE_2D, 0, GL_RED, uvWidth, uvHeight, 0, GL_RED, GL_UNSIGNED_BYTE, uPlane);

        // Upload V texture
        glActiveTexture(GL_TEXTURE2);
        glBindTexture(GL_TEXTURE_2D, textures_[2]);
        glPixelStorei(GL_UNPACK_ROW_LENGTH, vStride);
        glTexImage2D(GL_TEXTURE_2D, 0, GL_RED, uvWidth, uvHeight, 0, GL_RED, GL_UNSIGNED_BYTE, vPlane);

        // Draw fullscreen quad with YUV shader
        glUseProgram(shaderProgram_);
        glUniform1i(glGetUniformLocation(shaderProgram_, "yTex"), 0);
        glUniform1i(glGetUniformLocation(shaderProgram_, "uTex"), 1);
        glUniform1i(glGetUniformLocation(shaderProgram_, "vTex"), 2);

        glBegin(GL_TRIANGLE_STRIP);
        glTexCoord2f(0, 1); glVertex2f(-1, -1);
        glTexCoord2f(1, 1); glVertex2f( 1, -1);
        glTexCoord2f(0, 0); glVertex2f(-1,  1);
        glTexCoord2f(1, 0); glVertex2f( 1,  1);
        glEnd();

        glXSwapBuffers(display_, window_);
    }

    void resize(int width, int height) override {
        width_ = width;
        height_ = height;
        glViewport(0, 0, width, height);
    }

    void pause() override { active_ = false; }
    void resume() override { active_ = true; }
    bool isActive() const override { return active_; }

private:
    void cleanup() {
        if (context_) {
            glDeleteTextures(3, textures_);
            glDeleteProgram(shaderProgram_);
            glXDestroyContext(display_, context_);
        }
        if (display_) {
            XCloseDisplay(display_);
        }
    }

    void createShaderProgram() {
        const char* vsSource = R"(
            #version 120
            varying vec2 texCoord;
            void main() {
                texCoord = gl_MultiTexCoord0.xy;
                gl_Position = gl_Vertex;
            }
        )";

        const char* fsSource = R"(
            #version 120
            uniform sampler2D yTex;
            uniform sampler2D uTex;
            uniform sampler2D vTex;
            varying vec2 texCoord;
            void main() {
                float y = texture2D(yTex, texCoord).r;
                float u = texture2D(uTex, texCoord).r - 0.5;
                float v = texture2D(vTex, texCoord).r - 0.5;
                
                float r = y + 1.402 * v;
                float g = y - 0.344 * u - 0.714 * v;
                float b = y + 1.772 * u;
                
                gl_FragColor = vec4(clamp(r, 0.0, 1.0), clamp(g, 0.0, 1.0), clamp(b, 0.0, 1.0), 1.0);
            }
        )";

        GLuint vs = glCreateShader(GL_VERTEX_SHADER);
        glShaderSource(vs, 1, &vsSource, nullptr);
        glCompileShader(vs);

        GLuint fs = glCreateShader(GL_FRAGMENT_SHADER);
        glShaderSource(fs, 1, &fsSource, nullptr);
        glCompileShader(fs);

        shaderProgram_ = glCreateProgram();
        glAttachShader(shaderProgram_, vs);
        glAttachShader(shaderProgram_, fs);
        glLinkProgram(shaderProgram_);

        glDeleteShader(vs);
        glDeleteShader(fs);
    }

    Display* display_ = nullptr;
    Window window_ = 0;
    GLXContext context_ = nullptr;
    GLuint textures_[3] = {0};
    GLuint shaderProgram_ = 0;
    int width_ = 0, height_ = 0;
    bool active_ = false;
};

// Factory implementation for Linux
GpuRenderer* GpuRenderer::create() {
    return new GlRenderer();
}

} // namespace saferoom

#endif // __linux__
```

### 4.7 macOS Metal Renderer Ä°skeleti

```cpp
// ğŸ“ Yeni dosya: native/src/mac/metal_renderer.mm

#ifdef __APPLE__

#include "../gpu_renderer.h"
#import <Metal/Metal.h>
#import <MetalKit/MetalKit.h>
#import <Cocoa/Cocoa.h>

namespace saferoom {

/**
 * Metal implementation of GpuRenderer for macOS.
 */
class MetalRenderer : public GpuRenderer {
public:
    MetalRenderer() = default;
    ~MetalRenderer() override { cleanup(); }

    bool initialize(void* windowHandle, int width, int height) override {
        @autoreleasepool {
            NSView* view = (__bridge NSView*)windowHandle;
            
            device_ = MTLCreateSystemDefaultDevice();
            if (!device_) return false;

            // Create Metal layer
            metalLayer_ = [CAMetalLayer layer];
            metalLayer_.device = device_;
            metalLayer_.pixelFormat = MTLPixelFormatBGRA8Unorm;
            metalLayer_.framebufferOnly = YES;
            view.layer = metalLayer_;
            view.wantsLayer = YES;

            // Create command queue
            commandQueue_ = [device_ newCommandQueue];

            // Create YUV textures
            createTextures(width, height);
            
            // Create pipeline
            createPipeline();

            width_ = width;
            height_ = height;
            active_ = true;
            return true;
        }
    }

    void renderFrame(
        const uint8_t* yPlane, const uint8_t* uPlane, const uint8_t* vPlane,
        int yStride, int uStride, int vStride,
        int width, int height) override 
    {
        if (!active_) return;

        @autoreleasepool {
            // Update Y texture
            MTLRegion yRegion = MTLRegionMake2D(0, 0, width, height);
            [yTexture_ replaceRegion:yRegion mipmapLevel:0 withBytes:yPlane bytesPerRow:yStride];

            // Update UV textures
            int uvWidth = (width + 1) / 2;
            int uvHeight = (height + 1) / 2;
            MTLRegion uvRegion = MTLRegionMake2D(0, 0, uvWidth, uvHeight);
            [uTexture_ replaceRegion:uvRegion mipmapLevel:0 withBytes:uPlane bytesPerRow:uStride];
            [vTexture_ replaceRegion:uvRegion mipmapLevel:0 withBytes:vPlane bytesPerRow:vStride];

            // Get drawable and render
            id<CAMetalDrawable> drawable = [metalLayer_ nextDrawable];
            if (!drawable) return;

            MTLRenderPassDescriptor* passDesc = [MTLRenderPassDescriptor renderPassDescriptor];
            passDesc.colorAttachments[0].texture = drawable.texture;
            passDesc.colorAttachments[0].loadAction = MTLLoadActionClear;
            passDesc.colorAttachments[0].storeAction = MTLStoreActionStore;
            passDesc.colorAttachments[0].clearColor = MTLClearColorMake(0, 0, 0, 1);

            id<MTLCommandBuffer> cmdBuffer = [commandQueue_ commandBuffer];
            id<MTLRenderCommandEncoder> encoder = [cmdBuffer renderCommandEncoderWithDescriptor:passDesc];

            [encoder setRenderPipelineState:pipelineState_];
            [encoder setFragmentTexture:yTexture_ atIndex:0];
            [encoder setFragmentTexture:uTexture_ atIndex:1];
            [encoder setFragmentTexture:vTexture_ atIndex:2];
            [encoder drawPrimitives:MTLPrimitiveTypeTriangleStrip vertexStart:0 vertexCount:4];
            [encoder endEncoding];

            [cmdBuffer presentDrawable:drawable];
            [cmdBuffer commit];
        }
    }

    void resize(int width, int height) override {
        width_ = width;
        height_ = height;
        metalLayer_.drawableSize = CGSizeMake(width, height);
        createTextures(width, height);
    }

    void pause() override { active_ = false; }
    void resume() override { active_ = true; }
    bool isActive() const override { return active_; }

private:
    void cleanup() {
        active_ = false;
        yTexture_ = nil;
        uTexture_ = nil;
        vTexture_ = nil;
        pipelineState_ = nil;
        commandQueue_ = nil;
        device_ = nil;
        metalLayer_ = nil;
    }

    void createTextures(int width, int height) {
        MTLTextureDescriptor* yDesc = [MTLTextureDescriptor texture2DDescriptorWithPixelFormat:MTLPixelFormatR8Unorm
                                                                                         width:width
                                                                                        height:height
                                                                                     mipmapped:NO];
        yDesc.usage = MTLTextureUsageShaderRead;
        yTexture_ = [device_ newTextureWithDescriptor:yDesc];

        int uvWidth = (width + 1) / 2;
        int uvHeight = (height + 1) / 2;
        MTLTextureDescriptor* uvDesc = [MTLTextureDescriptor texture2DDescriptorWithPixelFormat:MTLPixelFormatR8Unorm
                                                                                          width:uvWidth
                                                                                         height:uvHeight
                                                                                      mipmapped:NO];
        uvDesc.usage = MTLTextureUsageShaderRead;
        uTexture_ = [device_ newTextureWithDescriptor:uvDesc];
        vTexture_ = [device_ newTextureWithDescriptor:uvDesc];
    }

    void createPipeline() {
        NSString* shaderSource = @R"(
            #include <metal_stdlib>
            using namespace metal;
            
            struct VertexOut {
                float4 position [[position]];
                float2 texCoord;
            };
            
            vertex VertexOut vertexMain(uint vertexID [[vertex_id]]) {
                float2 positions[] = { {-1,-1}, {1,-1}, {-1,1}, {1,1} };
                float2 texCoords[] = { {0,1}, {1,1}, {0,0}, {1,0} };
                
                VertexOut out;
                out.position = float4(positions[vertexID], 0, 1);
                out.texCoord = texCoords[vertexID];
                return out;
            }
            
            fragment float4 fragmentMain(VertexOut in [[stage_in]],
                                         texture2d<float> yTex [[texture(0)]],
                                         texture2d<float> uTex [[texture(1)]],
                                         texture2d<float> vTex [[texture(2)]]) {
                constexpr sampler s(filter::linear);
                float y = yTex.sample(s, in.texCoord).r;
                float u = uTex.sample(s, in.texCoord).r - 0.5;
                float v = vTex.sample(s, in.texCoord).r - 0.5;
                
                float r = y + 1.402 * v;
                float g = y - 0.344 * u - 0.714 * v;
                float b = y + 1.772 * u;
                
                return float4(saturate(float3(r, g, b)), 1.0);
            }
        )";

        NSError* error;
        id<MTLLibrary> library = [device_ newLibraryWithSource:shaderSource options:nil error:&error];
        
        MTLRenderPipelineDescriptor* pipelineDesc = [[MTLRenderPipelineDescriptor alloc] init];
        pipelineDesc.vertexFunction = [library newFunctionWithName:@"vertexMain"];
        pipelineDesc.fragmentFunction = [library newFunctionWithName:@"fragmentMain"];
        pipelineDesc.colorAttachments[0].pixelFormat = MTLPixelFormatBGRA8Unorm;
        
        pipelineState_ = [device_ newRenderPipelineStateWithDescriptor:pipelineDesc error:&error];
    }

    id<MTLDevice> device_;
    id<MTLCommandQueue> commandQueue_;
    id<MTLRenderPipelineState> pipelineState_;
    id<MTLTexture> yTexture_, uTexture_, vTexture_;
    CAMetalLayer* metalLayer_;
    int width_ = 0, height_ = 0;
    bool active_ = false;
};

// Factory implementation for macOS
GpuRenderer* GpuRenderer::create() {
    return new MetalRenderer();
}

} // namespace saferoom

#endif // __APPLE__
```

---

## 5. JAVAFX UI AYRIÅTIRMA STRATEJÄ°SÄ°

### 5.1 YaklaÅŸÄ±m KarÅŸÄ±laÅŸtÄ±rmasÄ±

| YaklaÅŸÄ±m | Avantaj | Dezavantaj | Uygulanabilirlik |
|----------|---------|------------|------------------|
| **SwingNode + LWJGL** | Mature, cross-platform | Swing overhead | â­â­â­ |
| **JFXPanel + AWT** | Basit entegrasyon | AWT/Swing karÄ±ÅŸÄ±mÄ± | â­â­ |
| **Overlay Window** | En hÄ±zlÄ± | Pencere yÃ¶netimi karmaÅŸÄ±k | â­â­â­â­ |
| **JavaFX Canvas + Dirty Regions** | Kolay implement | Hala CPU-bound | â­â­ |

### 5.2 Ã–nerilen Strateji: Hybrid Overlay

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        HYBRID OVERLAY ARCHITECTURE                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    Main JavaFX Window                        â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚    â”‚
â”‚  â”‚  â”‚                     UI LAYER                             â”‚â”‚    â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚â”‚    â”‚
â”‚  â”‚  â”‚  â”‚ Toolbar  â”‚ â”‚ Controls â”‚ â”‚ Labels   â”‚ â”‚ Buttons  â”‚   â”‚â”‚    â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚â”‚    â”‚
â”‚  â”‚  â”‚                                                         â”‚â”‚    â”‚
â”‚  â”‚  â”‚  [JavaFX Nodes - Transparent Background]                â”‚â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚    â”‚
â”‚  â”‚                              â”‚                               â”‚    â”‚
â”‚  â”‚                              â–¼                               â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚    â”‚
â”‚  â”‚  â”‚                    VIDEO LAYER                           â”‚â”‚    â”‚
â”‚  â”‚  â”‚                                                          â”‚â”‚    â”‚
â”‚  â”‚  â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚â”‚    â”‚
â”‚  â”‚  â”‚              â”‚  Native GPU Surface   â”‚                   â”‚â”‚    â”‚
â”‚  â”‚  â”‚              â”‚  (D3D11/Metal/GL)     â”‚                   â”‚â”‚    â”‚
â”‚  â”‚  â”‚              â”‚                       â”‚                   â”‚â”‚    â”‚
â”‚  â”‚  â”‚              â”‚  Direct Rendering     â”‚                   â”‚â”‚    â”‚
â”‚  â”‚  â”‚              â”‚  Zero CPU Copy        â”‚                   â”‚â”‚    â”‚
â”‚  â”‚  â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚â”‚    â”‚
â”‚  â”‚  â”‚                                                          â”‚â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.3 VideoPanel Refactoring

```java
// ğŸ“ DeÄŸiÅŸtirilecek dosya: src/main/java/com/saferoom/gui/components/VideoPanel.java

package com.saferoom.gui.components;

import com.saferoom.webrtc.gpu.NativeGpuRendererBridge;
import com.saferoom.webrtc.gpu.NativeVideoRenderer;
import com.saferoom.webrtc.pipeline.FrameProcessor;
import com.saferoom.webrtc.pipeline.FrameRenderResult;
import com.saferoom.util.PlatformDetector;
import dev.onvoid.webrtc.media.video.VideoTrack;
import dev.onvoid.webrtc.media.video.VideoTrackSink;
import javafx.application.Platform;
import javafx.scene.canvas.Canvas;
import javafx.scene.canvas.GraphicsContext;
import javafx.scene.image.PixelFormat;
import javafx.scene.image.PixelWriter;
import javafx.scene.image.WritableImage;
import javafx.scene.paint.Color;

import java.nio.IntBuffer;
import java.util.concurrent.atomic.AtomicReference;

/**
 * Video rendering panel with automatic mode selection.
 * 
 * Rendering Modes:
 * 1. GPU Mode (preferred): Native D3D11/Metal/OpenGL rendering
 *    - Zero CPU copy
 *    - YUVâ†’RGB in GPU shader
 *    - Direct texture upload
 * 
 * 2. Software Mode (fallback): JavaFX Canvas rendering
 *    - Used when GPU renderer unavailable
 *    - Uses optimized batch I420â†’ARGB conversion
 */
public class VideoPanel extends Canvas {

    // Rendering mode
    private enum RenderMode { GPU, SOFTWARE }
    private RenderMode renderMode = RenderMode.SOFTWARE;
    
    // GPU renderer (null if not available)
    private NativeVideoRenderer gpuRenderer;
    
    // Software renderer components
    private static final PixelFormat<IntBuffer> ARGB_FORMAT = PixelFormat.getIntArgbPreInstance();
    private final GraphicsContext gc;
    private final AtomicReference<FrameRenderResult> latestFrame = new AtomicReference<>();
    private WritableImage videoImage;
    private FrameProcessor frameProcessor;
    
    // Common state
    private VideoTrack videoTrack;
    private VideoTrackSink videoSink;
    private boolean isActive = false;

    public VideoPanel(double width, double height) {
        super(width, height);
        this.gc = getGraphicsContext2D();
        
        // Try to initialize GPU renderer
        initializeGpuRenderer();
        
        drawPlaceholder("No Video");
    }

    /**
     * Initialize GPU renderer if available.
     * Falls back to software rendering if GPU init fails.
     */
    private void initializeGpuRenderer() {
        try {
            // Get native window handle from JavaFX
            // This requires the window to be shown first
            Platform.runLater(() -> {
                if (getScene() != null && getScene().getWindow() != null) {
                    long windowHandle = getWindowHandle();
                    if (windowHandle != 0) {
                        gpuRenderer = new NativeGpuRendererBridge();
                        if (gpuRenderer.initialize(windowHandle, (int)getWidth(), (int)getHeight())) {
                            renderMode = RenderMode.GPU;
                            System.out.println("[VideoPanel] âœ… GPU rendering enabled");
                        } else {
                            gpuRenderer = null;
                            System.out.println("[VideoPanel] âš ï¸ GPU init failed, using software rendering");
                        }
                    }
                }
            });
        } catch (UnsatisfiedLinkError | Exception e) {
            System.out.println("[VideoPanel] GPU renderer not available: " + e.getMessage());
            renderMode = RenderMode.SOFTWARE;
        }
    }

    /**
     * Get native window handle for GPU renderer.
     * Platform-specific implementation.
     */
    private long getWindowHandle() {
        try {
            // This is simplified - actual implementation needs platform-specific code
            // Windows: GetWindowHandle via JNI
            // macOS: NSView pointer
            // Linux: X11 Window ID
            
            if (PlatformDetector.isWindows()) {
                // com.sun.glass.ui.Window access (internal API)
                // Or use JAWT for proper handle extraction
            }
            
            return 0; // TODO: Implement platform-specific window handle extraction
        } catch (Exception e) {
            return 0;
        }
    }

    /**
     * Attach a video track to this panel.
     * Automatically selects GPU or software rendering.
     */
    public void attachVideoTrack(VideoTrack track) {
        if (track == null) {
            System.err.println("[VideoPanel] Cannot attach null video track");
            return;
        }

        detachVideoTrack();
        this.videoTrack = track;
        this.isActive = true;

        if (renderMode == RenderMode.GPU && gpuRenderer != null) {
            // âœ… GPU Mode: Direct sink attachment
            videoSink = gpuRenderer::onVideoFrame;
            System.out.println("[VideoPanel] Using GPU rendering");
        } else {
            // âš ï¸ Software Mode: Through FrameProcessor
            frameProcessor = buildOptimizedFrameProcessor();
            videoSink = frame -> {
                if (frameProcessor != null) {
                    frameProcessor.submit(frame);
                }
            };
            startSoftwareAnimation();
            System.out.println("[VideoPanel] Using software rendering");
        }

        track.addSink(videoSink);
    }

    /**
     * Build optimized frame processor for software rendering.
     * Uses batch I420â†’ARGB conversion.
     */
    private FrameProcessor buildOptimizedFrameProcessor() {
        return new FrameProcessor(result -> latestFrame.set(result));
    }

    // ... rest of the class with existing software rendering code ...
}
```

---

## 6. SONUÃ‡ RAPORU VE TODO

### 6.1 Mevcut Durum Ã–zeti

| Metrik | Mevcut | Mikro Opt. SonrasÄ± | GPU SonrasÄ± |
|--------|--------|--------------------|-----------  |
| Kopya SayÄ±sÄ±/Frame | 5 | 3 | 1 |
| Memory Bandwidth | ~120 MB/s | ~60 MB/s | ~15 MB/s |
| CPU Usage (4 video) | 80-100% | 40-60% | 10-20% |
| Frame Processing Time | ~12ms | ~5ms | <1ms |
| GC Pressure | High | Medium | Low |

### 6.2 Ä°ncelenmesi Gereken Dosyalar

```
ğŸ“ MUTLAKA Ä°NCELE:
â”œâ”€â”€ src/main/java/com/saferoom/gui/components/VideoPanel.java
â”œâ”€â”€ src/main/java/com/saferoom/webrtc/pipeline/FrameProcessor.java
â”œâ”€â”€ src/main/java/com/saferoom/webrtc/pipeline/FrameRenderResult.java
â”œâ”€â”€ src/main/java/com/saferoom/webrtc/pipeline/ArgbBufferPool.java
â””â”€â”€ src/main/java/com/saferoom/webrtc/WebRTCClient.java (handleRemoteVideoTrack)

ğŸ“ YENÄ° DOSYALAR (GPU Pipeline iÃ§in):
â”œâ”€â”€ src/main/java/com/saferoom/webrtc/gpu/NativeVideoRenderer.java
â”œâ”€â”€ src/main/java/com/saferoom/webrtc/gpu/NativeGpuRendererBridge.java
â”œâ”€â”€ native/src/gpu_renderer.h
â”œâ”€â”€ native/src/win/d3d11_renderer.cpp
â”œâ”€â”€ native/src/linux/gl_renderer.cpp
â””â”€â”€ native/src/mac/metal_renderer.mm
```

### 6.3 TODO Listesi

```
âœ… TAMAMLANDI:
â”œâ”€â”€ [x] Mevcut pipeline analizi
â”œâ”€â”€ [x] Kopya noktalarÄ±nÄ±n tespiti
â”œâ”€â”€ [x] Mikro optimizasyon planÄ±
â””â”€â”€ [x] GPU renderer mimari tasarÄ±mÄ±

ğŸ”„ KISA VADE (1-2 hafta):
â”œâ”€â”€ [ ] FrameRenderResult.fromI420Optimized() implementasyonu
â”œâ”€â”€ [ ] Row-based bulk ByteBuffer read
â”œâ”€â”€ [ ] Frame rate throttling (30 FPS cap)
â”œâ”€â”€ [ ] WritableImage reuse optimization
â””â”€â”€ [ ] IntBuffer direct write test

ğŸ”„ ORTA VADE (2-4 hafta):
â”œâ”€â”€ [ ] NativeVideoRenderer interface finalize
â”œâ”€â”€ [ ] JNI bridge implementation
â”œâ”€â”€ [ ] Windows D3D11 renderer
â”œâ”€â”€ [ ] Linux OpenGL renderer
â”œâ”€â”€ [ ] macOS Metal renderer
â””â”€â”€ [ ] Window handle extraction (JAWT)

ğŸ”„ UZUN VADE (4-8 hafta):
â”œâ”€â”€ [ ] Multi-participant GPU compositing
â”œâ”€â”€ [ ] Hardware video decode integration
â”œâ”€â”€ [ ] Texture sharing (zero-copy from decoder)
â”œâ”€â”€ [ ] WebRTC native VideoSink bridge
â””â”€â”€ [ ] Performance benchmarking suite
```

### 6.4 Kritik UyarÄ±lar

```
âš ï¸ UYARI 1: JNI Thread Safety
   GPU renderer'dan gelen callback'ler native thread'de Ã§alÄ±ÅŸÄ±r.
   JavaFX node'larÄ±na doÄŸrudan eriÅŸme - Platform.runLater() kullan.

âš ï¸ UYARI 2: Resource Cleanup
   GPU texture'lar ve native handle'lar manuel cleanup gerektirir.
   Java GC bunlarÄ± temizlemez - dispose() Ã§aÄŸrÄ±sÄ± zorunlu.

âš ï¸ UYARI 3: Platform Testing
   Her platform farklÄ± GPU API kullanÄ±yor.
   Windows/macOS/Linux ayrÄ± ayrÄ± test edilmeli.

âš ï¸ UYARI 4: Fallback ZorunluluÄŸu
   GPU renderer baÅŸarÄ±sÄ±z olursa software rendering devreye girmeli.
   KullanÄ±cÄ±ya kesinti olmamalÄ±.
```

---

## REFERANSLAR

- [WebRTC Native API](https://webrtc.googlesource.com/src/)
- [dev.onvoid.webrtc Java Binding](https://github.com/nicokosi/webrtc-java)
- [JavaFX Internal Architecture](https://wiki.openjdk.org/display/OpenJFX/Main)
- [Direct3D 11 Programming Guide](https://docs.microsoft.com/en-us/windows/win32/direct3d11/)
- [Metal Programming Guide](https://developer.apple.com/metal/)
- [OpenGL Programming Guide](https://www.khronos.org/opengl/)

---

*Bu dokÃ¼man SafeRoom V2 video pipeline optimizasyonu iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r.*

